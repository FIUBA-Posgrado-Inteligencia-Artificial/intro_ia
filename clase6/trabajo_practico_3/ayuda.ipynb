{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae42b5cdc085ad0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:52:16.120115Z",
     "start_time": "2024-04-11T15:52:15.893237Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scikit-learn nos ofrece una variedad ampliada de modelos Naive Bayes, para este problema usamos MultinomialNB que es pensado para este tipo de problemas\n",
    "from sklearn.naive_bayes import MultinomialNB   \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadd4f97a897731c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# TP3: Detector de SPAM\n",
    "\n",
    "Uno de los problemas más comunes en la clasificación es la detección de correos electrónicos SPAM. Uno de los primeros modelos utilizados para abordar este problema fue el clasificador de Bayes ingenuo. La detección de SPAM es un problema persistente en el mundo digital, ya que los spammers continúan adaptando sus estrategias para eludir los filtros de correo no deseado. Además del clasificador de Bayes ingenuo, se han desarrollado y utilizado una variedad de técnicas más avanzadas en la detección de SPAM, que incluyen algoritmos de aprendizaje automático, redes neuronales y métodos basados en reglas.\n",
    "\n",
    "En este trabajo práctico, utilizaremos un conjunto de datos que consta de 4601 observaciones de correos electrónicos, de los cuales 2788 son correos legítimos y 1813 son correos SPAM. Dado que el contenido de los correos electrónicos es un tipo de dato no estructurado, es necesario procesarlo de alguna manera. Para este conjunto de datos, ya se ha aplicado un procesamiento típico en el Procesamiento del Lenguaje Natural (NLP), que consiste en contar la frecuencia de palabras observadas en los correos.\n",
    "\n",
    "El procesamiento de lenguaje natural (NLP) desempeña un papel fundamental en la detección de SPAM, ya que permite analizar el contenido de los correos electrónicos y extraer características relevantes para la clasificación. Además de contar la frecuencia de palabras, se pueden utilizar técnicas más sofisticadas, como la extracción de características semánticas y el análisis de sentimientos, para mejorar la precisión de los modelos de detección de SPAM.\n",
    "\n",
    "En este proceso, se cuenta la cantidad de ocurrencias de cada palabra en los diferentes correos.\n",
    "\n",
    "![spam counter](./spam.png)\n",
    "\n",
    "Con el fin de preservar la privacidad de los mensajes, la frecuencia de palabras se encuentra normalizada. El conjunto de datos está compuesto por 54 columnas de atributos que se denominan:\n",
    "\n",
    "- `word_freq_XXXX`: Donde `XXXX` es la palabra o símbolo. Los valores son enteros que van de 0 a 20k.\n",
    "\n",
    "Además, hay una columna adicional llamada `spam`, que es 1 si el correo es SPAM o 0 si no lo es.\n",
    "\n",
    "Los clasificadores de Bayes ingenuos fueron los primeros filtros utilizados por las aplicaciones de correo electrónico, basados en este principio de palabras. La idea es que, partiendo de un dato a priori sobre la probabilidad de que un correo sea SPAM o no, ciertas palabras nos indicarán que la probabilidad a posteriori, dadas esas palabras, es más probable que el correo sea SPAM o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:52:16.143226Z",
     "start_time": "2024-04-11T15:52:16.120715Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_edu</th>\n",
       "      <th>word_freq_table</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210</td>\n",
       "      <td>280</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>280</td>\n",
       "      <td>210</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>940</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>372</td>\n",
       "      <td>180</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>710</td>\n",
       "      <td>0</td>\n",
       "      <td>1230</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>120</td>\n",
       "      <td>640</td>\n",
       "      <td>250</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>184</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>630</td>\n",
       "      <td>310</td>\n",
       "      <td>630</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>630</td>\n",
       "      <td>310</td>\n",
       "      <td>630</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "      <td>610</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>920</td>\n",
       "      <td>760</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>203</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>120</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>320</td>\n",
       "      <td>380</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0               0                640            640             0   \n",
       "1             210                280            500             0   \n",
       "2              60                  0            710             0   \n",
       "3               0                  0              0             0   \n",
       "4               0                  0              0             0   \n",
       "5               0                  0              0             0   \n",
       "6               0                  0              0             0   \n",
       "7               0                  0              0             0   \n",
       "8             150                  0            460             0   \n",
       "9              60                120            770             0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0            320               0                 0                   0   \n",
       "1            140             280               210                  70   \n",
       "2           1230             190               190                 120   \n",
       "3            630               0               310                 630   \n",
       "4            630               0               310                 630   \n",
       "5           1850               0                 0                1850   \n",
       "6           1920               0                 0                   0   \n",
       "7           1880               0                 0                1880   \n",
       "8            610               0               300                   0   \n",
       "9            190             320               380                   0   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  word_freq_edu  word_freq_table  \\\n",
       "0                0               0  ...              0                0   \n",
       "1                0             940  ...              0                0   \n",
       "2              640             250  ...             60                0   \n",
       "3              310             630  ...              0                0   \n",
       "4              310             630  ...              0                0   \n",
       "5                0               0  ...              0                0   \n",
       "6                0             640  ...              0                0   \n",
       "7                0               0  ...              0                0   \n",
       "8              920             760  ...              0                0   \n",
       "9               60               0  ...              0                0   \n",
       "\n",
       "   word_freq_conference  char_freq_;  char_freq_(  char_freq_[  char_freq_!  \\\n",
       "0                     0            0            0            0          778   \n",
       "1                     0            0          132            0          372   \n",
       "2                     0           10          143            0          276   \n",
       "3                     0            0          137            0          137   \n",
       "4                     0            0          135            0          135   \n",
       "5                     0            0          223            0            0   \n",
       "6                     0            0           54            0          164   \n",
       "7                     0            0          206            0            0   \n",
       "8                     0            0          271            0          181   \n",
       "9                     0           40           30            0          244   \n",
       "\n",
       "   char_freq_$  char_freq_#  spam  \n",
       "0            0            0     1  \n",
       "1          180           48     1  \n",
       "2          184           10     1  \n",
       "3            0            0     1  \n",
       "4            0            0     1  \n",
       "5            0            0     1  \n",
       "6           54            0     1  \n",
       "7            0            0     1  \n",
       "8          203           22     1  \n",
       "9           81            0     1  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"dataset/spambase.csv\") # cargando los datos desde un CSV\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5762c49a3369dc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Para obtener las palábras más usadas podemos hacer un `groupby`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa93f67db28da6ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:52:16.147047Z",
     "start_time": "2024-04-11T15:52:16.143891Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "column_sum = dataset.groupby(by=\"spam\", as_index=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efab4e7c21dd0461",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Y despues se pueden combinar las columnas en usando [pd.melt](https://pandas.pydata.org/docs/reference/api/pandas.melt.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a05390e27958e98b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:52:16.150961Z",
     "start_time": "2024-04-11T15:52:16.147743Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Obtenemos los atributos y target\n",
    "X = (dataset.drop(columns=\"spam\") * 100).astype(int)\n",
    "#X = dataset2.drop(columns=\"spam\")\n",
    "y = dataset[\"spam\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686665f4a0ce53e5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Se separa el dataset en entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a05dd9a86a0270d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:52:16.155862Z",
     "start_time": "2024-04-11T15:52:16.151805Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deca5d28cadd43b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Escalamos para aplicar en regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "712e38ef8afee400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:52:16.162957Z",
     "start_time": "2024-04-11T15:52:16.156768Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Lo transformamos en DataFrames\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76a9e6364b4d74b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:52:16.168004Z",
     "start_time": "2024-04-11T15:52:16.164460Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
