{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización - Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(loc=0,scale=1,size=(200,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-2,2,50).reshape(50,1)\n",
    "y = 1 + 2*x + np.random.normal(loc=0,scale=1,size=(50,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a Dado el dataset anterior, calcular la forma cerrada de una regresión lineal considerando la ordenada al origen. \n",
    "\n",
    "$$w^* = (X^TX)^{-1} X^Ty $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b Calcular las predicciones sobre el dataset original\n",
    "\n",
    "$$\\hat{y}= X w^* $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c Calcular el error de las predicciones\n",
    "\n",
    "$$ e = y - \\hat{y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.d Computar el valor del gradiente\n",
    "\n",
    "\\begin{align}\n",
    "     \\nabla_w J(w) &= \\nabla_w \\Big( \\sum_{i} (y_i - X_i W)^2 \\Big) \\\\\n",
    "     &= \\sum_{i} \\Big( \\nabla_w (y_i - X_i W)^2 \\Big) \\\\\n",
    "    &=  \\sum_i \\Big( \\nabla_w (y_i - (x_{i1}w_1 + x_{i2}w_2+ \\cdots + x_{im}w_m))^2 \\Big)\\\\\n",
    "    &=  \\sum_i \\Big( -2 (y_i - \\hat{y}_i) x_{ij} \\Big) \\hspace{1cm} \\forall j \\in (1 \\cdots m)\\\\\n",
    "    &= \\begin{bmatrix} \\sum_i \\Big( -2 (y_i - \\hat{y}_i) x_{i1} \\Big) \\\\ \\vdots \\\\ \\sum_i \\Big( -2 (y_i - \\hat{y}_i) x_{im} \\Big) \\end{bmatrix}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.a Implementar gradient descent con Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for *epoch* in **n_epochs**:\n",
    "1. Calcular las predicciones para todas las muestras $\\hat{y}$\n",
    "2. Calcular el error entre la salida real y las predicciones.\n",
    "3. Calcular el gradiente usando todas las muestras.\n",
    "4. Actualizar todos los parámetros del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio: Implementar GD vectorizado en NumPy\n",
    "def gradient_descent(X_train, y_train, lr=0.01, epochs=100):\n",
    "\n",
    "\n",
    "    # Inicializar parámetros\n",
    "\n",
    "    for i in range(amt_epochs):\n",
    "        # Calcular predicciones\n",
    "        \n",
    "        # Calcular error\n",
    "\n",
    "        # Calcular gradientes\n",
    "\n",
    "        # Actualizar parámetros\n",
    "\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.b Implementar Stochastic Gradient Descent con Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for *epoch* in **n_epochs**:\n",
    "* Mezclar las muestras (shuffle)\n",
    "* for *sample* in **n_samples**:\n",
    "    1. Calcular la predicción para la muestra $\\hat{y_{i}}$\n",
    "    2. Calcular el error entre la salida real y la predicción.\n",
    "    3. Calcular el gradiente usando la muestra.\n",
    "    4. Actualizar todos los parámetros del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X_train, y_train, lr=0.01, amt_epochs=100):\n",
    "    \n",
    "    # Inicializar parámetros\n",
    "\n",
    "    # Iterate over the n_epochs\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        # Mezclar muestras / Tomar índices aleatorios\n",
    "\n",
    "        # Iterar sobre el dataset aplicando GD\n",
    "\n",
    "\n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.c Implementar Mini-Batch Gradient Descent con Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for *epoch* in **n_epochs**:\n",
    "* Mezclar los **batches** (shuffle)\n",
    "* for *batch* in **n_batches**:\n",
    "    1. Calcular las predicciones para el batch $\\hat{y_{batch}}$\n",
    "    2. Calcular el error entre las salidas reales del batch y las predicciones.\n",
    "    3. Calcular el gradiente para el batch.\n",
    "    4. Actualizar todos los parámetros del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_gradient_descent(X_train, y_train, lr=0.01, epochs=100, batch_size=16):\n",
    "    \n",
    "\n",
    "    # Inicializar parámetros\n",
    "   \n",
    "    # Iterar las epochs\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        # Mezclar samples / Índices aleatorios \n",
    "\n",
    " \n",
    "        # Iterar sobre los batches\n",
    "        \n",
    "        for i ...:\n",
    "            # Implementar Gradient Descent tomando los \"tramos\" de \n",
    "            # dataset correspondientes al batch\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.a Calcular los pesos con los tres algoritmos. Comparar los resultados entre sí y con la solución cerrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.b Computar los tiempos de ejecución de los cuatro métodos y comparar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizar %%timeit. Para más información ejecutar %%timeit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.4 ns ± 1.06 ns per loop (mean ± std. dev. of 5 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de timeit\n",
    "%%timeit -n 1000 -r 5 \n",
    "11 - 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
