{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae42b5cdc085ad0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:52:16.120115Z",
     "start_time": "2024-04-11T15:52:15.893237Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scikit-learn ofrece una variedad de modelos Naive Bayes. Para este problema, utilizamos MultinomialNB, que es adecuado para datos de conteo como este.\n",
    "from sklearn.naive_bayes import MultinomialNB   \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadd4f97a897731c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# TP3: Detector de SPAM\n",
    "\n",
    "Uno de los problemas más comunes en clasificación es la detección de correos electrónicos SPAM. Uno de los primeros modelos utilizados para abordar este problema fue el clasificador de Bayes ingenuo (Naive Bayes). La detección de SPAM sigue siendo un problema persistente en el mundo digital, ya que los spammers continúan adaptando sus estrategias para evadir los filtros de correo no deseado.\n",
    "\n",
    "Además del clasificador de Bayes ingenuo, se han desarrollado y utilizado técnicas más avanzadas, como algoritmos de aprendizaje automático, redes neuronales y métodos basados en reglas.\n",
    "\n",
    "En este trabajo práctico utilizaremos un conjunto de datos que contiene 4601 observaciones de correos electrónicos, de los cuales 2788 son legítimos y 1813 son SPAM. Como el contenido de los correos electrónicos es un tipo de dato no estructurado, es necesario procesarlo. En este caso, el dataset ya ha sido preprocesado utilizando técnicas típicas de Procesamiento de Lenguaje Natural (NLP), como el conteo de la frecuencia de palabras observadas en los correos.\n",
    "\n",
    "El procesamiento de lenguaje natural desempeña un rol fundamental en la detección de SPAM, ya que permite analizar el contenido textual y extraer características relevantes para la clasificación. Además del simple conteo de palabras, se pueden aplicar técnicas más sofisticadas, como la extracción de características semánticas o el análisis de sentimientos, para mejorar la precisión de los modelos.\n",
    "\n",
    "En este dataset, se cuenta la cantidad de ocurrencias de cada palabra en los distintos correos:\n",
    "\n",
    "![spam counter](./spam.png)\n",
    "\n",
    "Para preservar la privacidad de los mensajes, las frecuencias han sido normalizadas. El dataset está compuesto por 54 columnas de atributos denominadas:\n",
    "\n",
    "- `word_freq_XXXX`: donde `XXXX` representa una palabra o símbolo. Los valores son enteros que van de 0 a 20.000.\n",
    "\n",
    "Adicionalmente, hay una columna llamada `spam`, que toma el valor 1 si el correo es SPAM, y 0 si es legítimo.\n",
    "\n",
    "Los clasificadores de Bayes ingenuos fueron de los primeros filtros utilizados por aplicaciones de correo electrónico, y se basan en este principio: partiendo de una probabilidad a priori de que un correo sea SPAM, ciertas palabras pueden modificar esa probabilidad a posteriori, indicando con mayor o menor certeza si un mensaje es o no SPAM.\n",
    "\n",
    "### Carga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:52:16.143226Z",
     "start_time": "2024-04-11T15:52:16.120715Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_edu</th>\n",
       "      <th>word_freq_table</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210</td>\n",
       "      <td>280</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>280</td>\n",
       "      <td>210</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>940</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>372</td>\n",
       "      <td>180</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>710</td>\n",
       "      <td>0</td>\n",
       "      <td>1230</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>120</td>\n",
       "      <td>640</td>\n",
       "      <td>250</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>184</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>630</td>\n",
       "      <td>310</td>\n",
       "      <td>630</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>630</td>\n",
       "      <td>310</td>\n",
       "      <td>630</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "      <td>610</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>920</td>\n",
       "      <td>760</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>203</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>120</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>320</td>\n",
       "      <td>380</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0               0                640            640             0   \n",
       "1             210                280            500             0   \n",
       "2              60                  0            710             0   \n",
       "3               0                  0              0             0   \n",
       "4               0                  0              0             0   \n",
       "5               0                  0              0             0   \n",
       "6               0                  0              0             0   \n",
       "7               0                  0              0             0   \n",
       "8             150                  0            460             0   \n",
       "9              60                120            770             0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0            320               0                 0                   0   \n",
       "1            140             280               210                  70   \n",
       "2           1230             190               190                 120   \n",
       "3            630               0               310                 630   \n",
       "4            630               0               310                 630   \n",
       "5           1850               0                 0                1850   \n",
       "6           1920               0                 0                   0   \n",
       "7           1880               0                 0                1880   \n",
       "8            610               0               300                   0   \n",
       "9            190             320               380                   0   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  word_freq_edu  word_freq_table  \\\n",
       "0                0               0  ...              0                0   \n",
       "1                0             940  ...              0                0   \n",
       "2              640             250  ...             60                0   \n",
       "3              310             630  ...              0                0   \n",
       "4              310             630  ...              0                0   \n",
       "5                0               0  ...              0                0   \n",
       "6                0             640  ...              0                0   \n",
       "7                0               0  ...              0                0   \n",
       "8              920             760  ...              0                0   \n",
       "9               60               0  ...              0                0   \n",
       "\n",
       "   word_freq_conference  char_freq_;  char_freq_(  char_freq_[  char_freq_!  \\\n",
       "0                     0            0            0            0          778   \n",
       "1                     0            0          132            0          372   \n",
       "2                     0           10          143            0          276   \n",
       "3                     0            0          137            0          137   \n",
       "4                     0            0          135            0          135   \n",
       "5                     0            0          223            0            0   \n",
       "6                     0            0           54            0          164   \n",
       "7                     0            0          206            0            0   \n",
       "8                     0            0          271            0          181   \n",
       "9                     0           40           30            0          244   \n",
       "\n",
       "   char_freq_$  char_freq_#  spam  \n",
       "0            0            0     1  \n",
       "1          180           48     1  \n",
       "2          184           10     1  \n",
       "3            0            0     1  \n",
       "4            0            0     1  \n",
       "5            0            0     1  \n",
       "6           54            0     1  \n",
       "7            0            0     1  \n",
       "8          203           22     1  \n",
       "9           81            0     1  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"dataset/spambase.csv\") # Cargamos los datos desde un archivo CSV\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5762c49a3369dc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Para obtener las palabras más frecuentes según si el correo es SPAM o no, podemos agrupar por clase con `groupby`::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa93f67db28da6ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:52:16.147047Z",
     "start_time": "2024-04-11T15:52:16.143891Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "column_sum = dataset.groupby(by=\"spam\", as_index=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efab4e7c21dd0461",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Luego, se pueden combinar las columnas usando [pd.melt](https://pandas.pydata.org/docs/reference/api/pandas.melt.html) para facilitar la visualización.\n",
    "\n",
    "### Preparación de los datos\n",
    "\n",
    "Obtenemos los atributos y el target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a05390e27958e98b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:52:16.150961Z",
     "start_time": "2024-04-11T15:52:16.147743Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=\"spam\")\n",
    "y = dataset[\"spam\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686665f4a0ce53e5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### División del dataset en entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a05dd9a86a0270d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:52:16.155862Z",
     "start_time": "2024-04-11T15:52:16.151805Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deca5d28cadd43b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Escalado para regresión logística\n",
    "\n",
    "Aplicamos un escalado Min-Max para hacer uno diferente al tipico StandardScaler():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "712e38ef8afee400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:52:16.162957Z",
     "start_time": "2024-04-11T15:52:16.156768Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convertimos los arrays escalados a DataFrames\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a9e6364b4d74b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:52:16.168004Z",
     "start_time": "2024-04-11T15:52:16.164460Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
