{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaf94e0a",
      "metadata": {
        "id": "aaf94e0a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento de modelos de prueba\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Evaluación de modelos de prueba\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Partición de train-test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Crear datasets\n",
        "from sklearn.datasets import make_regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z4CnDndvBlc6",
      "metadata": {
        "id": "z4CnDndvBlc6"
      },
      "source": [
        "Vamos a crear un dataset sintetico utilizando las librerias de [Sklearn Datasets](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html), en particular nos interesa crear un problema de regresion\n",
        "lineal al que podemos variarle sus parametros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65843123",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65843123",
        "outputId": "6589754e-2630-4c3d-cd45-b5f10ad8dc49"
      },
      "outputs": [],
      "source": [
        "# Creamos un dataset de prueba\n",
        "X, y = make_regression(n_samples = 1000,\n",
        "                       n_features = 1,\n",
        "                       noise = 2,\n",
        "                       n_informative = 1,\n",
        "                       random_state = 42)\n",
        "\n",
        "new_data = np.append(X,y.reshape(-1,1),axis=1)\n",
        "new_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a52eSwfzCslx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "a52eSwfzCslx",
        "outputId": "51d2ef98-ff3b-4182-966e-a03b1a14ba1a"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(new_data)\n",
        "\n",
        "new_col = []\n",
        "i = 0\n",
        "for col in df.columns:\n",
        "    if i ==  len(df.columns) - 1:\n",
        "        new_col.append(\"target\")\n",
        "    else :\n",
        "        new_col.append(\"feature_\" + str(i+1))\n",
        "        \n",
        "    i += 1\n",
        "    \n",
        "df.columns = new_col\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CBb_QmSZCPFZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "CBb_QmSZCPFZ",
        "outputId": "a7c8b051-581d-4267-8bad-5db770be6740"
      },
      "outputs": [],
      "source": [
        "fig,axes = plt.subplots(2,figsize=(22,6))\n",
        "axes[0].scatter(X,y)\n",
        "sns.histplot(X, ax=axes[1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zTvu6e3KhEKG",
      "metadata": {
        "id": "zTvu6e3KhEKG"
      },
      "source": [
        "## Funciones auxiliares para generar datos anómalos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_LqDjS8chDkY",
      "metadata": {
        "id": "_LqDjS8chDkY"
      },
      "outputs": [],
      "source": [
        "def generate_nulls(df: pd.DataFrame,\n",
        "                   cols: list = None,\n",
        "                   percentage: float = 0.05) -> pd.DataFrame:\n",
        "  \"\"\"Con esta función vamos a poder generar nulos en ciertas columnas de nuestro\n",
        "  dataset.\n",
        "  \"\"\"  \n",
        "  cols = df.columns.tolist() if cols is None else cols\n",
        "  seeds = np.random.randint(100, size = len(cols))\n",
        "  \n",
        "  nsamples = np.math.floor(len(df) * percentage)\n",
        "\n",
        "  result = df.copy(deep = True)\n",
        "  for i,col_name in enumerate(cols):\n",
        "      np.random.seed(seeds[i])\n",
        "      \n",
        "      idx_to_remove = result[col_name].sample(n = nsamples).index\n",
        "      result[col_name].iloc[idx_to_remove] = np.nan if result[col_name].dtype in [int,float] else None\n",
        "  \n",
        "  return result\n",
        "\n",
        "def generate_outliers(df: pd.DataFrame,\n",
        "                     cols: list = None,\n",
        "                     extreme_outlier: bool = False,\n",
        "                     two_tailed: bool = False,\n",
        "                     percentage: float = 0.02) -> pd.DataFrame:\n",
        "  \"\"\"Con esta función vamos a poder generar outliers en ciertas columnas de nuestro\n",
        "  dataset. Si le damos True a _extreme_outlier_ va a generar outliers con mucho\n",
        "  peso en la regresión (puede ser bilateral o unilateral segun _two_tailed_)\n",
        "  \"\"\"  \n",
        "  seeds = np.random.randint(100, size = len(df))\n",
        "  \n",
        "  nsamples = np.math.floor(len(df) * percentage)\n",
        "  idx_to_change = df.sample(n = nsamples).index\n",
        "\n",
        "  cols = df.columns.tolist() if cols is None else cols\n",
        "\n",
        "  result = df.copy(deep = True)\n",
        "  \n",
        "  for i,col_name in enumerate(cols):\n",
        "    np.random.seed(seeds[i])\n",
        "\n",
        "    iqr = result[col_name].quantile(0.75) - result[col_name].quantile(0.25)\n",
        "\n",
        "    lb = result[col_name].quantile(0.25) - 1 * iqr\n",
        "    ub = result[col_name].quantile(0.75) + 1 * iqr\n",
        "\n",
        "    if two_tailed:\n",
        "      outs = result[col_name].loc[(result[col_name] < lb) | (result[col_name] > ub)]\n",
        "    else:\n",
        "      outs = result[col_name].loc[(result[col_name] > ub)]\n",
        "    \n",
        "    out_size = len(outs)\n",
        "    if out_size < nsamples:\n",
        "      nsamples = out_size\n",
        "\n",
        "    idx_to_change = outs.sample(nsamples, replace = False).index\n",
        "    \n",
        "    if extreme_outlier:\n",
        "      outlier_sign = [1 if np.random.random() < 0.9 else -1 for _ in range(nsamples)]\n",
        "      \n",
        "      result[col_name].loc[idx_to_change] = np.multiply(outlier_sign,\n",
        "                                                        np.random.uniform(low = result[col_name].mean(),\n",
        "                                                                          high = result[col_name].max()*5,\n",
        "                                                                          size = nsamples)\n",
        "                                                        )\n",
        "      result['target'].loc[idx_to_change] = np.multiply(outlier_sign,\n",
        "                                                        np.random.uniform(low = result['target'].mean(),\n",
        "                                                                          high = result['target'].max()*2,\n",
        "                                                                          size = nsamples)\n",
        "                                                        )\n",
        "    else:\n",
        "      samples = result[col_name].loc[idx_to_change].values\n",
        "      np.random.shuffle(samples)\n",
        "      result[col_name].loc[idx_to_change] = samples\n",
        "  \n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mmnwCbF1gugP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmnwCbF1gugP",
        "outputId": "a27810fe-1f0f-40ef-99ac-dace0fc0eb92"
      },
      "outputs": [],
      "source": [
        "df_outlier = generate_outliers(df,['feature_1'], percentage = 0.05, extreme_outlier = True, two_tailed= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b520928",
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.lmplot(data = pd.concat([df.assign(dataset = 'set1'),\n",
        "                                 df_outlier.assign(dataset = 'set2')]),\n",
        "                x = 'feature_1',\n",
        "                y = 'target',\n",
        "                hue = 'dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29PGZV_B4o79",
      "metadata": {
        "id": "29PGZV_B4o79"
      },
      "outputs": [],
      "source": [
        "columnas_a_modificar = ['feature_1'] \n",
        "df_missing = generate_nulls(df,columnas_a_modificar, percentage = 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1JOMgSjy43uf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JOMgSjy43uf",
        "outputId": "5b0f2496-a995-45e5-8335-b652fadc763b"
      },
      "outputs": [],
      "source": [
        "df_missing.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N_XkGtvw7J-i",
      "metadata": {
        "id": "N_XkGtvw7J-i"
      },
      "source": [
        "# Ejercicio 1\n",
        "\n",
        "Crear una función que separe los datos en train-validation-test 70-20-10\n",
        "\n",
        "\n",
        "Hints: \n",
        "\n",
        "* Usar Indexing y slicing\n",
        "* Usar np.random.[...]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yIOYdDHz7Jkp",
      "metadata": {
        "id": "yIOYdDHz7Jkp"
      },
      "outputs": [],
      "source": [
        "def split(df: pd.DataFrame, train_size: float):\n",
        "\n",
        "    return X_train, X_val, X_test, Y_train, Y_val, Y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c51994ab",
      "metadata": {
        "id": "c51994ab"
      },
      "source": [
        "# Ejercicio 2\n",
        "\n",
        "Utilizando la funcion `generate_nulls`. Insertar en la columna de features un 5% de valores nulos. Con esto, generar una función que les permita rellenar estos valores con la mediana, y otro con la media.\n",
        "\n",
        "Compare los __scores__ obtenidos en las regresiones cuando tiene el dataset completo, y con los dos métodos de imputación. ¿Cambian mucho?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8c44b25",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.feature_1.median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de6919a5",
      "metadata": {
        "id": "de6919a5",
        "outputId": "55fef8af-0856-44b5-b46a-3f8be4d28fb9"
      },
      "outputs": [],
      "source": [
        "def mean_imputer(df: pd.DataFrame, columns: str) -> pd.DataFrame:\n",
        "    pass\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Uq2ZEyio66-p",
      "metadata": {
        "id": "Uq2ZEyio66-p"
      },
      "outputs": [],
      "source": [
        "def median_imputer(df: pd.DataFrame, columns: str) -> pd.DataFrame:\n",
        "    pass\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "808ffcaa",
      "metadata": {
        "id": "808ffcaa"
      },
      "source": [
        "# Ejercicio 3\n",
        "\n",
        "Los resultados del ejercicio 1 ¿Cómo se ven afectados cuando empezamos a a tener muchos más valores imputados? Pruebe con distintos porcentajes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b5U2d0C6agm",
      "metadata": {
        "id": "6b5U2d0C6agm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b77ad81a",
      "metadata": {
        "id": "b77ad81a"
      },
      "source": [
        "# Ejercicio 4\n",
        "\n",
        "Utilizando la funcion `generate_outliers` generar puntos extremos dentro de los datos que generamos anteriormente. En este ejercicio dejar setteado `extreme_outliers` como `False` y observe como variando el porcentaje de los mismos la regresión comienza a afectarse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VKkw3PwY8JC7",
      "metadata": {
        "id": "VKkw3PwY8JC7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d481762b",
      "metadata": {
        "id": "d481762b"
      },
      "source": [
        "# Ejercicio 5\n",
        "\n",
        "Generar ahora valores extremos utilizando `extreme_outliers`. ¿Cómo afecta esto a la regresión? ¿Se observa algo interesante?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34b43474",
      "metadata": {
        "id": "34b43474"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "tkxP2BID8XqM",
      "metadata": {
        "id": "tkxP2BID8XqM"
      },
      "source": [
        "# Ejercicio 6\n",
        "\n",
        "utilizando el archivo CSV `clase3v2.csv`, vamos a cargarlo como dataframe y deberemos:\n",
        " - Generar splits de training/test\n",
        " - Limpiar/Imputar datos Nulos\n",
        " - Entrenar un modelo de regresión simple\n",
        " - Reportar $R^2$ en test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vv1_2NZ78w9x",
      "metadata": {
        "id": "vv1_2NZ78w9x"
      },
      "outputs": [],
      "source": [
        "data_happiness = pd.read_csv('clase3v2.csv', delimiter = ';')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hCNvuKcF8-fM",
      "metadata": {
        "id": "hCNvuKcF8-fM"
      },
      "source": [
        "# Ejercicio 6\n",
        "\n",
        "Por último, manteniendo un dataset limpio como el que generamos previo al ejercio 1, utilizando `make_regression` de `scikit-learn`. Analizar que pasa si comenzamos a modificar el parametro `noise`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Os_Et7Ww9V6I",
      "metadata": {
        "id": "Os_Et7Ww9V6I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Practica_clase_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "b5c22da4a52024410f64f9c5a5e2b4ffeeb944a5ed00e8825a42174cdab30315"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
