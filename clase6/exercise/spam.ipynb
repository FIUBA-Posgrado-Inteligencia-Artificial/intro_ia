{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fadd4f97a897731c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Ejercicio Módulo 6 - Detector de SPAM\n",
    "**Inteligencia Artificial - CEIA - FIUBA**\n",
    "\n",
    "**INSERTE AQUÍ SU NOMBRE**\n",
    "\n",
    "Uno de los problemas más comunes en clasificación es la detección de correos electrónicos no deseados (SPAM). Uno de los primeros modelos utilizados para abordar este problema fue el clasificador de Bayes ingenuo (Naive Bayes). La detección de SPAM sigue siendo un desafío en el mundo digital, ya que los emisores de este tipo de mensajes continúan adaptando sus estrategias para evadir los filtros.\n",
    "\n",
    "Además del clasificador de Bayes ingenuo, se han desarrollado y aplicado técnicas más avanzadas, como algoritmos de aprendizaje automático, redes neuronales y métodos basados en reglas.\n",
    "\n",
    "En este ejercicio utilizaremos un conjunto de datos que contiene 4601 observaciones de correos electrónicos, de los cuales 2788 son legítimos y 1813 son SPAM. Dado que el contenido de los correos es un tipo de dato no estructurado, es necesario procesarlo. En este caso, el dataset ya ha sido preprocesado utilizando técnicas típicas de Procesamiento de Lenguaje Natural (NLP), como el conteo de la frecuencia de palabras observadas en los mensajes.\n",
    "\n",
    "El procesamiento de lenguaje natural desempeña un rol fundamental en la detección de SPAM, ya que permite analizar el contenido textual y extraer características relevantes para la clasificación. Además del simple conteo de palabras, pueden aplicarse técnicas más sofisticadas, como la extracción de características semánticas o el análisis de sentimientos, para mejorar la precisión de los modelos.\n",
    "\n",
    "En este dataset, se contabiliza la cantidad de ocurrencias de cada palabra en los distintos correos:\n",
    "\n",
    "![spam counter](./spam.png)\n",
    "\n",
    "Para preservar la privacidad de los mensajes, las frecuencias han sido normalizadas. El dataset está compuesto por 54 columnas de atributos denominadas:\n",
    "\n",
    "- `word_freq_XXXX`: donde `XXXX` representa una palabra o símbolo. Los valores son enteros que van de 0 a 20.000.\n",
    "\n",
    "Adicionalmente, incluye una columna llamada `spam`, que toma el valor 1 si el correo es SPAM, y 0 si es legítimo.\n",
    "\n",
    "Los clasificadores de Bayes ingenuos fueron de los primeros filtros utilizados por las aplicaciones de correo electrónico. Se basan en el siguiente principio: partiendo de una probabilidad a priori de que un correo sea SPAM, la aparición de ciertas palabras puede modificar esa probabilidad a posteriori, indicando con mayor o menor certeza si un mensaje es o no SPAM.\n",
    "\n",
    "### Carga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:52:16.143226Z",
     "start_time": "2024-04-11T15:52:16.120715Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv(\"dataset/spambase.csv\") # Cargamos los datos desde un archivo CSV\n",
    "dataset.head(10)\n",
    "\n",
    "X = dataset.iloc[:, :-1] # Seleccionamos todas las filas y todas las columnas menos la última como características\n",
    "y = dataset.iloc[:, -1]  # Seleccionamos todas las filas y solo la última columna como etiquetas\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # Dividimos los datos en conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deca5d28cadd43b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Armado de modelos\n",
    "\n",
    "En esta sección completaremos las partes que faltan:\n",
    "\n",
    "- Cree una regresión logística utilizando un **Pipeline** de scikit-learn que incluya una etapa de estandarización de los atributos.\n",
    "- Cree un modelo de **Bayes ingenuo** (sin aplicar normalización). Seleccione la implementación que considere más apropiada para este problema de entre las que ofrece scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee4acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# COMPLETAR: Importar las librerías necesarias\n",
    "\n",
    "# Creamos el pipeline de regresion logistica\n",
    "log_reg = Pipeline([\n",
    "   # COMPLETAR: Agregar una etapa de estandarización\n",
    "   # COMPLETAR: Agregar la regresión logística\n",
    "])\n",
    "\n",
    "# Creamos el modelo Bayesiano Ingenuo\n",
    "naive_bayes = # COMPLETAR: Crear el modelo de Bayes Ingenuo\n",
    "\n",
    "# Entrenamos los modelos\n",
    "log_reg.fit(X_train, y_train)\n",
    "naive_bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54afa856",
   "metadata": {},
   "source": [
    "### Evaluación de modelos:\n",
    "\n",
    "Para cada modelo, utilizando el dataset de evaluación, calcule:\n",
    "\n",
    "- La **matriz de confusión**\n",
    "- La **precisión (precision)** y la **recuperación (recall)**\n",
    "- El **AUC (Área Bajo la Curva ROC)**\n",
    "\n",
    "#### Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a9e6364b4d74b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:52:16.168004Z",
     "start_time": "2024-04-11T15:52:16.164460Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Evaluamos el modelo de regresion logistica\n",
    "y_pred_logreg = log_reg.predict(X_test)\n",
    "y_prob_logreg = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculamos las métricas\n",
    "cm_logreg = # COMPLETAR: Calcular la matriz de confusión\n",
    "precision_logreg = # COMPLETAR: Calcular la precisión\n",
    "recall_logreg = # COMPLETAR: Calcular el recall\n",
    "roc_auc_logreg = # COMPLETAR: Calculamos el AUC. OBS: Usamos las probabilidades para AUC\n",
    "\n",
    "print('Regresión Logística:')\n",
    "print(f'  Precisión: {precision_logreg}')\n",
    "print(f'  Recall: {recall_logreg}')\n",
    "print(f'  AUC: {roc_auc_logreg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8284b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_logreg = ConfusionMatrixDisplay(confusion_matrix=cm_logreg)\n",
    "disp_logreg.plot()\n",
    "plt.title('Matriz de Confusión - Regresión Logística')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0e8996",
   "metadata": {},
   "source": [
    "#### Modelo Bayesiano Ingenuo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfeab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el modelo naive-bayes\n",
    "y_pred_nb = naive_bayes.predict(X_test)\n",
    "y_prob_nb = naive_bayes.predict_proba(X_test)[:, 1]\n",
    "\n",
    "cm_nb = # ... \n",
    "precision_nb = # ... \n",
    "recall_nb = # ... \n",
    "roc_auc_nb = # ... \n",
    "\n",
    "print('Naive Bayes:')\n",
    "print(f'  Precisión: {precision_nb}')\n",
    "print(f'  Recall: {recall_nb}')\n",
    "print(f'  AUC: {roc_auc_nb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f518b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_logreg = ConfusionMatrixDisplay(confusion_matrix=cm_nb)\n",
    "disp_logreg.plot()\n",
    "plt.title('Matriz de Confusión - Naive Bayes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d1663",
   "metadata": {},
   "source": [
    "Completa la tabla de métricas:\n",
    "\n",
    "| Modelo                        | Precision | Recall | AUC | \n",
    "| ----------------------------- | --- | --- | ----- |\n",
    "| Regresión Logistica              |     |     |       |\n",
    "| Naive Bayes |     |     |       |\n",
    "\n",
    "\n",
    "### Preguntas:\n",
    "\n",
    "¿Cuál es el mejor modelo según cada métrica?\n",
    "\n",
    "- Precision: ...\n",
    "- Recall: ...\n",
    "- AUC: ...\n",
    "\n",
    "Viendo la matriz de confusión, ¿qué tipo de error comete más cada modelo?\n",
    "\n",
    "- Regresión logística: ...\n",
    "- Modelo Bayes ingenuo: ...\n",
    "\n",
    "Según tu opinión, ¿cuál de los dos tipos de error considerás más importante en este problema?\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro-ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
