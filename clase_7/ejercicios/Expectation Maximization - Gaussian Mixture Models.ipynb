{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation Maximization - GMMs NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En éste notebook vamos a aplicar los conceptos teóricos del método iterativo de expectation maximization para estimar los parámetros de un Gaussian Mixture Model en NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos las Liberías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../../clase_3/ejercicios/src')\n",
    "sys.path.insert(0, '../../clase_1/ejercicios/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BaseModel\n",
    "from metrics import Accuracy, Precision, Recall\n",
    "from k_means_numpy import k_means, k_means_classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Maximization para GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vamos a introducir los building blocks de cada uno de los pasos de EM para los Gaussian Mixture Models. Finalizaremos la sección armando un modelo de GMM con la misma estructura de BaseModel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Inicialización de Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El primer paso de EM es inicializar los parámetros del modelo\n",
    "# (probabilidades, medias y covarianzas de los componentes)\n",
    "\n",
    "# Indicamos la cantidad de componentes\n",
    "k = 2\n",
    "\n",
    "# Inicializamos y normalizamos las probabilidades (kx1)\n",
    "p = np.random.uniform(0, 1, (k, 1))\n",
    "p = p / np.sum(p, axis=0)\n",
    "\n",
    "# Inicializamos las medias dentro del rango de los datos (kx1)\n",
    "means = np.random.uniform(np.min(X), np.max(X), (k, 1))\n",
    "\n",
    "# Inicalizamos la varianza a partir de los datos y las medias escogidas (kx1).\n",
    "# Estamos usando broadcasting para el cálculo.\n",
    "covariance = np.sum((np.hstack((X, X))- means.T)**2, axis=0)/(X.shape[0]-1)\n",
    "covariance = covariance.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. E-Step: cálculo de responsabilidades (a posteriori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinen las responsabilidades $\\omega_{k}$ para cada componente y cada muestra. Para ello, deben calcular la pdf de la distribución normal multivariada. Hint: usen multivariate_normal.pdf de Scipy. $ \\omega_{k} = \\frac{\\pi_{k} * \\mathcal{N}(x_n | \\mu_k, \\Sigma_k  ) }{\\sum_{j}^{}\\pi_{j} * \\mathcal{N}(x_n | \\mu_j, \\Sigma_j  )} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armen una matriz para almacenar los resultados de la pdf de cada muestra para cada componente (nxk)\n",
    "\n",
    "Nij = np.zeros((n, k))\n",
    "\n",
    "for j in range(k):\n",
    "    Nij[:, j] = multivariate_normal.pdf(X, means[j], covariance[j])\n",
    "\n",
    "# Armen una matriz para almacenar las responsabilidades de cada muestra y cada componente (nxk)\n",
    "\n",
    "Eij = np.zeros((n, k))\n",
    "\n",
    "for j in range(k):\n",
    "    Eij[:, j] = (p[j] * Nij[:, j]) / (Nij @ p)[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. M-Step: redeterminación de parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mu_{j} = \\frac{\\sum_{i=1}^{N}\\omega_{j}^{(i)}x^{(i)}}{\\sum_{i=1}^{N}\\omega_{j}^{(i)}}$\n",
    "\n",
    "$\\pi_{j} = \\frac{1}{N}\\sum_{i=1}^{N}\\omega_{j}^{(i)}$ \n",
    "\n",
    "$\\Sigma_{j} = \\frac{\\sum_{i=1}^{N}\\omega_{j}^{(i)}(x^{(i)}-\\mu_j)(x^{(i)}-\\mu_j)^T}{\\sum_{i=1}^{N}\\omega_{j}^{(i)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con los valores calculados de las responsabilidades, recalcular los parámetros\n",
    "\n",
    "# Redeterminar las medias\n",
    "means[j] = (Eij[:, j].dot(X)) / np.sum(Eij[:, j], axis=0)\n",
    "\n",
    "# Redeterminar la covarianza\n",
    "covariance[j] = Eij[:, j].dot((X - means[j]) * (X - means[j])) / np.sum(Eij[:, j])\n",
    "\n",
    "# Redeterminar las probabilidades\n",
    "p[j] = np.mean(Eij[:, j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los bloques anteriores, armar un método fit que reciba X, y y la cantidad de clusters y retorne como resultado los parámetros del modelo de GMM (probabilidades, medias y covarianzas de cada componente). Al ser un algoritmo iterativo, es importante determinar un criterio de parada. Se suele utilizar un número máximos de iteraciones MAX_ITER y simultáneamente se  evalúa la diferencia entre los parámetros de la iteración actual y la anterior, para ver si se modifican por sobre determinada tolerancia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, k):\n",
    "    # Paso 1: Inicialización parámetros\n",
    "    # Loop con criterio de parada (MAX_ITER, tol):\n",
    "        # Paso 2: E-Step\n",
    "        # Paso 3: M-Step\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez determinados los parámetros de cada componente del GMM, cuando recibimos una nueva muestra, debemos usar los mísmos para calcular las responsabilidades (probabilidades a posteriori) de cada componente para esa muestra y devolver como \"cluster\", el componente cuya probabilidad sea mayor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    \n",
    "    # Calculamos las responsabilidades de cada muestra para cada componente\n",
    "    N = np.zeros((X.shape[0], k))\n",
    "    E = np.zeros((X.shape[0], k))\n",
    "    \n",
    "    for i in range(k):\n",
    "        N[:, i] = multivariate_normal.pdf(X, self.model['mu'][i, 0], self.model['cov'][i, 0])\n",
    "    \n",
    "    for i in range(k):\n",
    "        E[:, i] = (self.model['p'][i, 0] * N[:, i]) / (N @ self.model['p'])[:, 0]\n",
    "    \n",
    "    # Devolvemos como cluster, el componente de máxima probabilidad para cada muestra\n",
    "    idx = np.argmax(E, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMScalar(BaseModel):\n",
    "    \n",
    "    def fit(self, X):\n",
    "\n",
    "        MAX_IT = 500\n",
    "\n",
    "        # Dimensions\n",
    "        n = X.shape[0]\n",
    "        k = 2\n",
    "\n",
    "        # Parameters initialization\n",
    "        p = np.random.uniform(0, 1, (k, 1))\n",
    "        p = p / np.sum(p, axis=0)\n",
    "        \n",
    "        means = np.random.uniform(np.min(X), np.max(X), (k, 1))\n",
    "        \n",
    "        covariance = np.sum((np.hstack((X, X))-means.T)**2, axis=0)/(X.shape[0]-1)\n",
    "        covariance = covariance.reshape(-1, 1)\n",
    "        \n",
    "        Nij = np.zeros((n, k))\n",
    "        Eij = np.zeros((n, k))\n",
    "        Eij_ant = np.zeros((n, k))\n",
    "\n",
    "        i = 0\n",
    "        delta = False\n",
    "        tol = 1E-5\n",
    "        for j in range(k):\n",
    "            Nij[:, j] = multivariate_normal.pdf(X, means[j], covariance[j])\n",
    "\n",
    "        # Execution Loop\n",
    "        while not (delta or i > MAX_IT):\n",
    "            Eij_ant[:, :] = Eij\n",
    "            for j in range(k):\n",
    "                Eij[:, j] = (p[j] * Nij[:, j]) / (Nij @ p)[:, 0]\n",
    "                means[j] = (Eij[:, j].dot(X)) / np.sum(Eij[:, j], axis=0)\n",
    "                covariance[j] = Eij[:, j].dot((X - means[j]) * (X - means[j])) / np.sum(Eij[:, j])\n",
    "                p[j] = np.mean(Eij[:, j])\n",
    "                Nij[:, j] = multivariate_normal.pdf(X, means[j], covariance[j])\n",
    "            delta = np.allclose(Eij_ant, Eij, rtol=tol)\n",
    "            i = i + 1\n",
    "        idx = np.argsort(means[:, 0], axis=0)\n",
    "        self.model = {'mu': means[idx, :], 'cov': covariance[idx, :], 'p': p[idx, :]}\n",
    "\n",
    "    def predict(self, X):\n",
    "        k = self.model['mu'].shape[0]\n",
    "        N = np.zeros((X.shape[0], k))\n",
    "        E = np.zeros((X.shape[0], k))\n",
    "\n",
    "        for i in range(k):\n",
    "            N[:, i] = multivariate_normal.pdf(X, self.model['mu'][i, 0], self.model['cov'][i, 0])\n",
    "        for i in range(k):\n",
    "            E[:, i] = (self.model['p'][i, 0] * N[:, i]) / (N @ self.model['p'])[:, 0]\n",
    "        idx = np.argmax(E, axis=1)\n",
    "        return idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
