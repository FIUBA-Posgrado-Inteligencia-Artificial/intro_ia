{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T21:57:55.166098Z",
     "start_time": "2024-04-04T21:57:55.163688Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de modelo\n",
    "**Facundo A. Lucianna - Inteligencia Artificial - CEIA - FIUBA**\n",
    "\n",
    "Previamente, tuvimos nuestro modelo de regresión múltiple, el cual mostró un rendimiento muy bueno. Ahora surge la pregunta: ¿Podemos obtener un modelo igual o similar utilizando menos atributos? Nuestro análisis estadístico inicial sugiere que algunos atributos podrían estar de más.\n",
    "\n",
    "Recordemos que un modelo más simple, con menos atributos, es preferible porque reduce la complejidad del modelo, mejora la interpretabilidad, disminuye el riesgo de sobreajuste y puede resultar en un modelo más eficiente.\n",
    "\n",
    "Por lo tanto, realizaremos una selección de modelo mediante el método de eliminación hacia atrás, utilizando el **criterio de información de Akaike (AIC)** para determinar si un atributo aporta significativamente al modelo.\n",
    "\n",
    "Comencemos creando una función que nos permita calcular el AIC usando la fórmula que desarrollamos previamente en la parte teórica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aic_criterion(y: np.ndarray, y_pred: np.ndarray, num_attributes: int) -> float:\n",
    "    \"\"\"\n",
    "    Calcula el Criterio de Información de Akaike (AIC) para un modelo de regresión lineal.\n",
    "\n",
    "    Este criterio se utiliza para la selección de modelos, penalizando la complejidad del modelo \n",
    "    (el número de parámetros) y favoreciendo a los modelos que tienen un buen ajuste a los datos \n",
    "    sin sobreajustar.\n",
    "\n",
    "    Args:\n",
    "        y (numpy.ndarray): El vector de valores reales de la variable dependiente (target).\n",
    "        y_pred (numpy.ndarray): El vector de valores predichos por el modelo de regresión.\n",
    "        num_attributes (int): El número de atributos (características) utilizados en el modelo.\n",
    "\n",
    "    Returns:\n",
    "        float: El valor del Criterio de Información de Akaike (AIC) para el modelo.\n",
    "    \"\"\"\n",
    "    # Agregamos uno porque hay que incorporar a la ordenada al origen\n",
    "    d = num_attributes + 1\n",
    "    N = y.shape[0]\n",
    "\n",
    "    # Calculamos los residuos al cuadrado\n",
    "    residuals = y - y_pred\n",
    "    Se = np.sum(residuals**2)\n",
    "\n",
    "    # Calculamos la estimación del logaritmo de maxima similitud de la regresión lineal\n",
    "    log_lik = np.log(2*np.pi) + np.log(Se/N) + 1\n",
    "    log_lik *= -N/2\n",
    "\n",
    "    #Calculamos ambos criterios\n",
    "    aic = 2*d - 2*log_lik \n",
    "   \n",
    "    return aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, carguemos el dataset completo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.472793Z",
     "start_time": "2024-03-28T18:21:54.466897Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"datasets/50_Startups.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que necesitamos entrenar varios modelos, primero realizamos la separación del dataset y el preprocesamiento de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dataset.drop(columns='Profit')\n",
    "y = dataset[\"Profit\"]\n",
    "\n",
    "# Usamos random_state=42 para asegurar que el split del dataset sea consistente con el anterior notebook\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, armemos el preprocesador que aplicará el `One-Hot Encoding` a las variables categóricas y la estandarización a las variables numéricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "categorical_columns = ['State']\n",
    "numerical_columns = ['R&D Spend', 'Administration', 'Marketing Spend']\n",
    "\n",
    "# Creamos el preprocesamiento para las columnas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_columns), \n",
    "        ('num', StandardScaler(), numerical_columns)   \n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar el siguiente trabajo, transformamos las salidas del preprocesador en un dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat__State_Florida</th>\n",
       "      <th>cat__State_New York</th>\n",
       "      <th>num__R&amp;D Spend</th>\n",
       "      <th>num__Administration</th>\n",
       "      <th>num__Marketing Spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.309487</td>\n",
       "      <td>0.946637</td>\n",
       "      <td>-0.855429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.966618</td>\n",
       "      <td>-1.507490</td>\n",
       "      <td>-0.536649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.533444</td>\n",
       "      <td>-0.285870</td>\n",
       "      <td>0.613821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.561500</td>\n",
       "      <td>0.484311</td>\n",
       "      <td>-1.963166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.880982</td>\n",
       "      <td>-0.018786</td>\n",
       "      <td>0.307319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat__State_Florida  cat__State_New York  num__R&D Spend  \\\n",
       "0                 0.0                  0.0        1.309487   \n",
       "1                 1.0                  0.0       -0.966618   \n",
       "2                 1.0                  0.0       -1.533444   \n",
       "3                 0.0                  0.0       -1.561500   \n",
       "4                 0.0                  1.0        0.880982   \n",
       "\n",
       "   num__Administration  num__Marketing Spend  \n",
       "0             0.946637             -0.855429  \n",
       "1            -1.507490             -0.536649  \n",
       "2            -0.285870              0.613821  \n",
       "3             0.484311             -1.963166  \n",
       "4            -0.018786              0.307319  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed = pd.DataFrame(X_train_processed, columns=preprocessor.get_feature_names_out())\n",
    "\n",
    "X_train_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas del array `X_train_processed` es:\n",
    "- 0: `'cat__State_Florida'`\n",
    "- 1: `'cat__State_New York'`\n",
    "- 2: `'num__R&D Spend'`\n",
    "- 3: `'num__Administration'`\n",
    "- 4: `'num__Marketing Spend'`\n",
    "\n",
    "Ahora, vamos a armar el modelo utilizando todos los atributos y calcular el AIC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC inicial es 749.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regresion = LinearRegression()\n",
    "regresion.fit(X_train_processed, y_train)\n",
    "y_pred = regresion.predict(X_train_processed)\n",
    "\n",
    "aic = aic_criterion(y_train, y_pred, X_train_processed.shape[1])\n",
    "\n",
    "print(f\"AIC inicial es {np.round(aic)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, creamos una función que, dada una selección de columnas, entrena un modelo y obtiene el AIC. Esto nos ayudará a ir avanzando paso a paso en la eliminación de atributos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_reg_model(X: pd.DataFrame, y: np.ndarray, columns: list) -> float:\n",
    "    \"\"\"\n",
    "    Entrena un modelo de regresión lineal y calcula el Criterio de Información de Akaike (AIC) para el modelo.\n",
    "\n",
    "    Esta función realiza lo siguiente:\n",
    "    1. Selecciona las columnas especificadas del conjunto de datos de características.\n",
    "    2. Entrena un modelo de regresión lineal utilizando las características seleccionadas y la variable dependiente.\n",
    "    3. Realiza las predicciones con el modelo entrenado.\n",
    "    4. Calcula el AIC utilizando las predicciones y las características del modelo.\n",
    "\n",
    "    Args:\n",
    "        X (pandas.DataFrame): El DataFrame de características (atributos) de las observaciones.\n",
    "        y (numpy.ndarray): El vector de valores reales de la variable dependiente (target).\n",
    "        columns (list): Una lista de las columnas que se deben seleccionar de `X` para entrenar el modelo.\n",
    "\n",
    "    Returns:\n",
    "        float: El valor del Criterio de Información de Akaike (AIC) para el modelo entrenado.\n",
    "    \"\"\"\n",
    "    X_clear = X.loc[:, columns].copy()\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_clear, y)\n",
    "    y_pred = model.predict(X_clear)\n",
    "\n",
    "    return aic_criterion(y, y_pred, X_clear.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto, estamos listos para realizar la eliminación de atributos hacia atrás y evaluar el rendimiento del modelo a medida que vamos simplificándolo.\n",
    "\n",
    "### Eliminación hacia atrás\n",
    "\n",
    "Ya hemos creado el primer modelo con todos los atributos, y obtuvimos un AIC de `749`. Ahora, entrenaremos varios modelos eliminando uno de los cinco atributos en cada paso, y observaremos cómo cambia el valor del AIC. Aplicaremos un enfoque greedy, eligiendo siempre eliminar el atributo que más reduzca el AIC. Continuaremos este proceso hasta que eliminar un atributo no mejore más el AIC.\n",
    "\n",
    "A continuación, entrenamos 5 modelos diferentes, eliminando un atributo en cada caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.508008Z",
     "start_time": "2024-03-28T18:21:54.502974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si sacamos a cat__State_Florida, AIC nos da:\n",
      "AIC 746.9\n",
      "Si sacamos a cat__State_New York, AIC nos da:\n",
      "AIC 747.0\n",
      "Si sacamos a num__R&D Spend, AIC nos da:\n",
      "AIC 820.5\n",
      "Si sacamos a num__Administration, AIC nos da:\n",
      "AIC 748.8\n",
      "Si sacamos a num__Marketing Spend, AIC nos da:\n",
      "AIC 748.7\n"
     ]
    }
   ],
   "source": [
    "# cat__State_Florida\n",
    "col = ['cat__State_New York', 'num__R&D Spend',\n",
    "       'num__Administration', 'num__Marketing Spend']\n",
    "aic = train_reg_model(X_train_processed, y_train, col)\n",
    "print(f\"Si sacamos a {X_train_processed.columns[0]}, AIC nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "\n",
    "# cat__State_New York\n",
    "col = ['cat__State_Florida', 'num__R&D Spend',\n",
    "       'num__Administration', 'num__Marketing Spend']\n",
    "aic = train_reg_model(X_train_processed, y_train, col)\n",
    "print(f\"Si sacamos a {X_train_processed.columns[1]}, AIC nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "\n",
    "# num__R&D Spend\n",
    "col = ['cat__State_Florida', 'cat__State_New York',\n",
    "       'num__Administration', 'num__Marketing Spend']\n",
    "aic = train_reg_model(X_train_processed, y_train, col)\n",
    "print(f\"Si sacamos a {X_train_processed.columns[2]}, AIC nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "\n",
    "# num__Administration\n",
    "col = ['cat__State_Florida', 'cat__State_New York', 'num__R&D Spend',\n",
    "       'num__Marketing Spend']\n",
    "aic = train_reg_model(X_train_processed, y_train, col)\n",
    "print(f\"Si sacamos a {X_train_processed.columns[3]}, AIC nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "\n",
    "# num__Marketing Spend\n",
    "col = ['cat__State_Florida', 'cat__State_New York', 'num__R&D Spend',\n",
    "       'num__Administration']\n",
    "aic = train_reg_model(X_train_processed, y_train, col)\n",
    "print(f\"Si sacamos a {X_train_processed.columns[4]}, AIC nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De estos 5 modelos, el mejor es el que tiene eliminado `'cat__State_Florida'`, lo que reduce el AIC de `749` a `746.9`. Ahora, seguimos con el siguiente paso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si sacamos a cat__State_New York, AIC nos da:\n",
      "AIC 745.1\n",
      "Si sacamos a num__R&D Spend, AIC nos da:\n",
      "AIC 819.0\n",
      "Si sacamos a num__Administration, AIC nos da:\n",
      "AIC 746.8\n",
      "Si sacamos a num__Marketing Spend, AIC nos da:\n",
      "AIC 746.9\n"
     ]
    }
   ],
   "source": [
    "# cat__State_New York\n",
    "col = ['num__R&D Spend', 'num__Administration', 'num__Marketing Spend']\n",
    "aic = train_reg_model(X_train_processed, y_train, col)\n",
    "print(f\"Si sacamos a {X_train_processed.columns[1]}, AIC nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "\n",
    "# num__R&D Spend\n",
    "col = ['cat__State_New York', 'num__Administration', 'num__Marketing Spend']\n",
    "aic = train_reg_model(X_train_processed, y_train, col)\n",
    "print(f\"Si sacamos a {X_train_processed.columns[2]}, AIC nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "\n",
    "# num__Administration\n",
    "col = ['cat__State_New York', 'num__R&D Spend', 'num__Marketing Spend']\n",
    "aic = train_reg_model(X_train_processed, y_train, col)\n",
    "print(f\"Si sacamos a {X_train_processed.columns[3]}, AIC nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "\n",
    "# num__Marketing Spend\n",
    "col = ['cat__State_New York', 'num__R&D Spend', 'num__Administration']\n",
    "aic = train_reg_model(X_train_processed, y_train, col)\n",
    "print(f\"Si sacamos a {X_train_processed.columns[4]}, AIC nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De estos 4 modelos, el mejor es el que tiene eliminado `'State_New_York'`, lo que reduce el AIC de `746.9` a `745.1`. Ahora, seguimos con el siguiente paso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si sacamos a num__R&D Spend, AIC nos da:\n",
      "AIC 817.1\n",
      "Si sacamos a num__Administration, AIC nos da:\n",
      "AIC 744.9\n",
      "Si sacamos a num__Marketing Spend, AIC nos da:\n",
      "AIC 745.2\n"
     ]
    }
   ],
   "source": [
    "# num__R&D Spend\n",
    "col = ['num__Administration', 'num__Marketing Spend']\n",
    "aic = train_reg_model(X_train_processed, y_train, col)\n",
    "print(f\"Si sacamos a {X_train_processed.columns[2]}, AIC nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "\n",
    "# num__Administration\n",
    "col = ['num__R&D Spend', 'num__Marketing Spend']\n",
    "aic = train_reg_model(X_train_processed, y_train, col)\n",
    "print(f\"Si sacamos a {X_train_processed.columns[3]}, AIC nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "\n",
    "# num__Marketing Spend\n",
    "col = ['num__R&D Spend', 'num__Administration']\n",
    "aic = train_reg_model(X_train_processed, y_train, col)\n",
    "print(f\"Si sacamos a {X_train_processed.columns[4]}, AIC nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que al quitar  `'Administration'`, el modelo mejora, pasando de un AIC de `745.1` a `744.9`. Ahora, veamos si podemos seguir eliminando atributos y verificar si un modelo con solo un atributo es mejor que el modelo con todos los atributos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si sacamos a num__R&D Spend, AIC nos da:\n",
      "AIC 817.7\n",
      "Si sacamos a num__Marketing Spend, AIC nos da:\n",
      "AIC 746.7\n"
     ]
    }
   ],
   "source": [
    "# num__R&D Spend\n",
    "col = ['num__Marketing Spend']\n",
    "aic = train_reg_model(X_train_processed, y_train, col)\n",
    "print(f\"Si sacamos a {X_train_processed.columns[2]}, AIC nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "\n",
    "# num__Marketing Spend\n",
    "col = ['num__R&D Spend']\n",
    "aic = train_reg_model(X_train_processed, y_train, col)\n",
    "print(f\"Si sacamos a {X_train_processed.columns[4]}, AIC nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí observamos que:\n",
    "- Al eliminar `'num__R&D Spend'`, el AIC es `817.7`, lo que es mayor que el AIC anterior de `745.1`.\n",
    "- Al eliminar `'num__Marketing Spend'`, el AIC es `746.7`, que también es mayor que el AIC anterior de `745.1`.\n",
    "\n",
    "Es decir, ninguno de estos casos mejora el modelo. Por lo tanto, el mejor modelo que encontramos es el que mantiene los atributos:\n",
    "\n",
    "- `'num__R&D Spend'`\n",
    "- `'num__Marketing Spend'`\n",
    "\n",
    "Recordemos que estos atributos eran los que mostraban la mejor correlación con respecto a la variable objetivo (`Profit`).\n",
    "\n",
    "---\n",
    "\n",
    "## Entrenamiento y evaluación de modelo más simple\n",
    "\n",
    "Con la selección realizada, ahora obtenemos el modelo, lo entrenamos y evaluamos con el set de evaluación.\n",
    "\n",
    "**Nota**: Obsérvese que nunca usamos el dataset de evaluación para la selección de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de la intersección de la recta es 111235.21\n",
      "Los valores de los coeficientes de la recta son [36450.28  4483.09]\n",
      "El coeficiente de determinación (R^2) es 0.95\n",
      "Desvío estándar del modelo 9719.15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Nos quedamos solo con las columnas que nos interesan del dataset\n",
    "numerical_columns_selected = ['R&D Spend', 'Marketing Spend']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns_selected)   \n",
    "    ]\n",
    ")\n",
    "\n",
    "# Creamos el pipeline con preprocesamiento y modelo\n",
    "pipeline_simple = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())  # Aplicamos la regresión lineal\n",
    "])\n",
    "\n",
    "# Entrenamos el modelo\n",
    "pipeline_simple.fit(X_train, y_train)\n",
    "\n",
    "# Resultados del entrenamiento:\n",
    "print(f\"El valor de la intersección de la recta es {np.round(pipeline_simple.named_steps['regressor'].intercept_, 2)}\")\n",
    "print(f\"Los valores de los coeficientes de la recta son {np.round(pipeline_simple.named_steps['regressor'].coef_, 2)}\")\n",
    "\n",
    "print(f\"El coeficiente de determinación (R^2) es {round(pipeline_simple.score(X_train, y_train), 2)}\")\n",
    "\n",
    "y_model = pipeline_simple.predict(X_train)\n",
    "num_attributes = len(pipeline_simple.named_steps['preprocessor'].get_feature_names_out())\n",
    "\n",
    "std_dev_model = np.sqrt((np.sum((y_train - y_model)**2))/(y_train.size - num_attributes - 1))\n",
    "print(f\"Desvío estándar del modelo {round(std_dev_model, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya podemos ver que el ajuste del modelo es prácticamente igual al que obtuvimos con todos los atributos.\n",
    "\n",
    "Veamos ahora las métricas con respecto al set de evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-cuadrado en test: 0.953\n",
      "Error absoluto medio: 6449.238\n",
      "Error cuadrático medio: 66537675.847\n",
      "Raíz de error cuadrático medio: 8157.063\n",
      "Error absoluto porcentual medio: 7.34%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (r2_score, mean_absolute_error, \n",
    "                             mean_squared_error, root_mean_squared_error, \n",
    "                             mean_absolute_percentage_error)\n",
    "\n",
    "y_pred = pipeline_simple.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(\"R-cuadrado en test:\", round(r2, 3))\n",
    "print(\"Error absoluto medio:\", round(mae, 3))\n",
    "print(\"Error cuadrático medio:\", round(mse, 3))\n",
    "print(\"Raíz de error cuadrático medio:\", round(rmse, 3))\n",
    "print(f\"Error absoluto porcentual medio: {mape*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora comparemos el modelo con respecto al modelo de base y al modelo completo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-cuadrado en test: -0.005\n",
      "Error absoluto medio: 30301.288\n",
      "Error cuadrático medio: 1413716446.334\n",
      "Raiz de error cuadrático medio: 37599.421\n",
      "Error absoluto porcentual medio: 35.79%\n"
     ]
    }
   ],
   "source": [
    "# Modelo baseline\n",
    "mean_profit = np.mean(y_train)\n",
    "\n",
    "y_pred_baseline = np.full_like(y_test, mean_profit)\n",
    "\n",
    "r2_baseline = r2_score(y_test, y_pred_baseline)\n",
    "mae_baseline = mean_absolute_error(y_test, y_pred_baseline)\n",
    "mse_baseline = mean_squared_error(y_test, y_pred_baseline)\n",
    "rmse_baseline = root_mean_squared_error(y_test, y_pred_baseline)\n",
    "mape_baseline = mean_absolute_percentage_error(y_test, y_pred_baseline)\n",
    "\n",
    "print(\"R-cuadrado en test:\", round(r2_baseline, 3))\n",
    "print(\"Error absoluto medio:\", round(mae_baseline, 3))\n",
    "print(\"Error cuadrático medio:\", round(mse_baseline, 3))\n",
    "print(\"Raiz de error cuadrático medio:\", round(rmse_baseline, 3))\n",
    "print(f\"Error absoluto porcentual medio: {mape_baseline*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-cuadrado en test: 0.94\n",
      "Error absoluto medio: 7395.434\n",
      "Error cuadrático medio: 84826955.035\n",
      "Raíz de error cuadrático medio: 9210.155\n",
      "Error absoluto porcentual medio: 8.93%\n"
     ]
    }
   ],
   "source": [
    "# Modelo con todos los atributos\n",
    "import joblib\n",
    "\n",
    "with open('reg_completo_50_startup.pkl', 'rb') as archivo:\n",
    "    pipeline_complete = joblib.load(archivo)\n",
    "\n",
    "y_pred_complete = pipeline_complete.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred_complete)\n",
    "mae = mean_absolute_error(y_test, y_pred_complete)\n",
    "mse = mean_squared_error(y_test, y_pred_complete)\n",
    "rmse = root_mean_squared_error(y_test, y_pred_complete)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred_complete)\n",
    "\n",
    "print(\"R-cuadrado en test:\", round(r2, 3))\n",
    "print(\"Error absoluto medio:\", round(mae, 3))\n",
    "print(\"Error cuadrático medio:\", round(mse, 3))\n",
    "print(\"Raíz de error cuadrático medio:\", round(rmse, 3))\n",
    "print(f\"Error absoluto porcentual medio: {mape*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparación de modelos:\n",
    "\n",
    "|                   | $R^2$      | MAE ($)   | RMSE ($) | MAPE (%) |\n",
    "|-------------------|------------|-----------|----------|----------|\n",
    "| Baseline          | -0.005     | 30301     | 3759     | 35.79    |\n",
    "| Modelo completo   | 0.94       | 7395      | 9210     | 8.93     |\n",
    "| **Modelo simple** | **0.953**  | **6449**  | **8157** | **7.34** |\n",
    "\n",
    "En esta tabla se observa que, en este caso, menos atributos ajustan mejor con el set de evaluación. Obsérvese que esto no siempre ocurre al usar AIC, ya que este criterio solo nos asegura encontrar modelos más simples, pero puede que no siempre se obtengan métricas de regresión mejores. Esto se debe a que al reducir los atributos, sacrificamos parte de la información, pero en este caso, el modelo más simple ha logrado una mejor generalización y un ajuste superior.\n",
    "\n",
    "Este modelo es mucho más simple, ya que utiliza solo dos atributos de la startup, lo que nos da una aproximación bastante precisa de sus ganancias anuales. Esto significa que, si el modelo se implementa en producción, será mucho más sencillo de mantener. No solo por la simplicidad en el número de atributos, sino también porque, al contar con un modelo más reducido, será menos costoso computacionalmente y más fácil de actualizar si se requieren cambios.\n",
    "\n",
    "Por último, guardemos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reg_simple_50_startup.pkl', 'wb') as archivo:\n",
    "    joblib.dump(pipeline_simple, archivo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
