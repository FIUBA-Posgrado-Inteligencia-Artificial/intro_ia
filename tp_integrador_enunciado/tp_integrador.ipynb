{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "07289bb0",
      "metadata": {},
      "source": [
        "# Trabajo práctico integrador\n",
        "\n",
        "**Nombre**:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afa76473",
      "metadata": {},
      "source": [
        "## Primera Parte (Clase 1 y 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaf94e0a",
      "metadata": {
        "id": "aaf94e0a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ffe9554",
      "metadata": {},
      "source": [
        "### Primer ejercicio\n",
        "\n",
        "Dada una matriz en formato *numpy array*, donde cada fila de la matriz representa un vector matemático, se requiere computar las normas $l_0$, $l_1$, $l_2$, $l_{\\infty}$, según la siguientes definiciones:\n",
        "\n",
        "\\begin{equation}\n",
        "    ||\\mathbf{x}||^{p} = \\bigg(\\sum_{j=1}^{n}{|x_i|^p}\\bigg)^{\\frac{1}{p}}\n",
        "\\end{equation}\n",
        "\n",
        "con los casos especiales para $p=0$ y $p=\\infty$ siendo:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\begin{array}{rcl}\n",
        "        ||\\mathbf{x}||_0 & = & \\bigg(\\sum_{j=1 \\wedge x_j != 0}{|x_i|}\\bigg)\\\\\n",
        "        ||\\mathbf{x}||_{\\infty} & = & \\max_{i}{|x_i|}\\\\\n",
        "    \\end{array}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bdb0ee3",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "dd66d862",
      "metadata": {},
      "source": [
        "### Segundo Ejercicio\n",
        "\n",
        "En clasificación contamos con dos arreglos, la “verdad” y la “predicción”. Cada elemento de los arreglos pueden tomar dos valores, “True” (representado por 1) y “False” (representado por 0). Entonces podemos definir 4 variables:\n",
        "\n",
        "* True Positive (TP): El valor verdadero es 1 y el valor predicho es 1\n",
        "* True Negative (TN): El valor verdadero es 0 y el valor predicho es 0\n",
        "* False Positive (FP): El valor verdadero es 0 y el valor predicho es 1\n",
        "* False Negative (FN): El valor verdadero es 1 y el valor predicho es 0\n",
        "\n",
        "A partir de esto definimos:\n",
        "\n",
        "* Precision = TP / (TP + FP)\n",
        "* Recall = TP / (TP + FN)\n",
        "* Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        " \n",
        "Calcular las 3 métricas con Numpy y operaciones vectorizadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "794dcd58",
      "metadata": {},
      "outputs": [],
      "source": [
        "truth = np.array([1,1,0,1,1,1,0,0,0,1])\n",
        "prediction = np.array([1,1,1,1,0,0,1,1,0,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "612a03e6",
      "metadata": {},
      "source": [
        "### Tercer y Cuarto Ejercicio\n",
        "\n",
        "Para este ejercicio vamos a considerar los siguientes datasets:\n",
        "\n",
        "* [HAR](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) (Ejercicio 3)\n",
        "* [MNIST](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) (Ejercicio 4)\n",
        "\n",
        "1. Aplicar PCA (validar que se cumplan las condiciones), ¿Cuántas componentes necesitamos para explicar el 80% de la varianza?\n",
        "2. Gráficar la variación acumulada para cada caso.\n",
        "3. Utilizando [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html). Agrupar el dataset transformado (ejercicio de PCA) y agrupar en clusters de $k=6$ (ej 3) y $k=10$ (ej 4). Luego en ambos casos probar con $k=2$.\n",
        "4. Graficar los resultados con los distintos k's usando las primeras dos componentes principales como ejes x,y.\n",
        "5. Explique. ¿Cuál fue la ganancia de usar PCA en conjunto con k-means?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ffbe422",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7c7574fd",
      "metadata": {},
      "source": [
        "## Segunda Parte (Clase 3 y 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaf94e0a",
      "metadata": {
        "id": "aaf94e0a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento de modelos de prueba\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Evaluación de modelos de prueba\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Crear datasets\n",
        "from sklearn.datasets import make_regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z4CnDndvBlc6",
      "metadata": {
        "id": "z4CnDndvBlc6"
      },
      "source": [
        "Vamos a crear un dataset sintetico utilizando las librerias de [Sklearn Datasets](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html), en particular nos interesa crear un problema de regresion\n",
        "lineal al que podemos variarle sus parametros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65843123",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65843123",
        "outputId": "6589754e-2630-4c3d-cd45-b5f10ad8dc49"
      },
      "outputs": [],
      "source": [
        "# Creamos un dataset de prueba\n",
        "X, y = make_regression(n_samples = 1000,\n",
        "                       n_features = 1,\n",
        "                       noise = 2,\n",
        "                       n_informative = 1,\n",
        "                       random_state = 42)\n",
        "\n",
        "new_data = np.append(X,y.reshape(-1,1),axis=1)\n",
        "new_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a52eSwfzCslx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "a52eSwfzCslx",
        "outputId": "51d2ef98-ff3b-4182-966e-a03b1a14ba1a"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(new_data)\n",
        "\n",
        "new_col = []\n",
        "i = 0\n",
        "for col in df.columns:\n",
        "    if i ==  len(df.columns) - 1:\n",
        "        new_col.append(\"target\")\n",
        "    else :\n",
        "        new_col.append(\"feature_\" + str(i+1))\n",
        "        \n",
        "    i += 1\n",
        "    \n",
        "df.columns = new_col\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CBb_QmSZCPFZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "CBb_QmSZCPFZ",
        "outputId": "a7c8b051-581d-4267-8bad-5db770be6740"
      },
      "outputs": [],
      "source": [
        "fig,axes = plt.subplots(2,figsize=(22,6))\n",
        "axes[0].scatter(X,y)\n",
        "sns.histplot(X, ax=axes[1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zTvu6e3KhEKG",
      "metadata": {
        "id": "zTvu6e3KhEKG"
      },
      "source": [
        "### Funciones auxiliares para generar datos anómalos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_LqDjS8chDkY",
      "metadata": {
        "id": "_LqDjS8chDkY"
      },
      "outputs": [],
      "source": [
        "def generate_outliers(df: pd.DataFrame,\n",
        "                     cols: list = None,\n",
        "                     extreme_outlier: bool = False,\n",
        "                     two_tailed: bool = False,\n",
        "                     percentage: float = 0.02) -> pd.DataFrame:\n",
        "  \"\"\"Con esta función vamos a poder generar outliers en ciertas columnas de nuestro\n",
        "  dataset. Si le damos True a _extreme_outlier_ va a generar outliers con mucho\n",
        "  peso en la regresión (puede ser bilateral o unilateral segun _two_tailed_)\n",
        "  \"\"\"  \n",
        "  seeds = np.random.randint(100, size = len(df))\n",
        "  \n",
        "  nsamples = np.math.floor(len(df) * percentage)\n",
        "  idx_to_change = df.sample(n = nsamples).index\n",
        "\n",
        "  cols = df.columns.tolist() if cols is None else cols\n",
        "\n",
        "  result = df.copy(deep = True)\n",
        "  \n",
        "  for i,col_name in enumerate(cols):\n",
        "    np.random.seed(seeds[i])\n",
        "\n",
        "    iqr = result[col_name].quantile(0.75) - result[col_name].quantile(0.25)\n",
        "\n",
        "    lb = result[col_name].quantile(0.25) - 1 * iqr\n",
        "    ub = result[col_name].quantile(0.75) + 1 * iqr\n",
        "\n",
        "    if two_tailed:\n",
        "      outs = result[col_name].loc[(result[col_name] < lb) | (result[col_name] > ub)]\n",
        "    else:\n",
        "      outs = result[col_name].loc[(result[col_name] > ub)]\n",
        "    \n",
        "    out_size = len(outs)\n",
        "    if out_size < nsamples:\n",
        "      nsamples = out_size\n",
        "\n",
        "    idx_to_change = outs.sample(nsamples, replace = False).index\n",
        "    \n",
        "    if extreme_outlier:\n",
        "      outlier_sign = [1 if np.random.random() < 0.9 else -1 for _ in range(nsamples)]\n",
        "      \n",
        "      result[col_name].loc[idx_to_change] = np.multiply(outlier_sign,\n",
        "                                                        np.random.uniform(low = result[col_name].mean(),\n",
        "                                                                          high = result[col_name].max()*5,\n",
        "                                                                          size = nsamples)\n",
        "                                                        )\n",
        "      result['target'].loc[idx_to_change] = np.multiply(outlier_sign,\n",
        "                                                        np.random.uniform(low = result['target'].mean(),\n",
        "                                                                          high = result['target'].max()*2,\n",
        "                                                                          size = nsamples)\n",
        "                                                        )\n",
        "    else:\n",
        "      samples = result[col_name].loc[idx_to_change].values\n",
        "      np.random.shuffle(samples)\n",
        "      result[col_name].loc[idx_to_change] = samples\n",
        "  \n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mmnwCbF1gugP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmnwCbF1gugP",
        "outputId": "a27810fe-1f0f-40ef-99ac-dace0fc0eb92"
      },
      "outputs": [],
      "source": [
        "df_outlier = generate_outliers(df,['feature_1'], percentage = 0.05, extreme_outlier = True, two_tailed= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b520928",
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.lmplot(data = pd.concat([df.assign(dataset = 'set1'),\n",
        "                                 df_outlier.assign(dataset = 'set2')]),\n",
        "                x = 'feature_1',\n",
        "                y = 'target',\n",
        "                hue = 'dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N_XkGtvw7J-i",
      "metadata": {
        "id": "N_XkGtvw7J-i"
      },
      "source": [
        "### Quinto ejercicio\n",
        "\n",
        "Crear una función que separe los datos en train-validation-test 70-20-10\n",
        "\n",
        "\n",
        "Hints: \n",
        "\n",
        "* Usar Indexing y slicing\n",
        "* Usar np.random.[...]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yIOYdDHz7Jkp",
      "metadata": {
        "id": "yIOYdDHz7Jkp"
      },
      "outputs": [],
      "source": [
        "def split(df: pd.DataFrame, train_size: float):\n",
        "\n",
        "    return X_train, X_val, X_test, Y_train, Y_val, Y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b77ad81a",
      "metadata": {
        "id": "b77ad81a"
      },
      "source": [
        "### Sexto ejercicio\n",
        "\n",
        "Utilizando la funcion `generate_outliers` generar puntos extremos dentro de los datos que generamos anteriormente. En este ejercicio dejar setteado `extreme_outliers` como `False` y observe como variando el porcentaje de los mismos la regresión comienza a afectarse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25e7924e",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ee6d1602",
      "metadata": {},
      "source": [
        "## Tercera Parte (Clase 5 y 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "933e2956",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5110aba0",
      "metadata": {},
      "source": [
        "## Cuarta Parte (Clase 3 y 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0273f4d0",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Practica_clase_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "b5c22da4a52024410f64f9c5a5e2b4ffeeb944a5ed00e8825a42174cdab30315"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
